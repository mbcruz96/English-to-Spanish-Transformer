{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8W1AiWnCgUTw",
        "hZvx0Hizsbbm",
        "P2cI5_R85J9X",
        "sIP3vGMZgYqt",
        "0hmkyXWxgcoz",
        "GVCEYiEr4eF2"
      ],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMO5k7mIPqUKS2yL1yuhCZU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbcruz96/English-to-Spanish-Transformer/blob/main/English_to_Spanish_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Libraries"
      ],
      "metadata": {
        "id": "8W1AiWnCgUTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install tokenizers\n",
        "!pip install tqdm\n",
        "!pip install tensorboard\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UtBhCHg5nAa",
        "outputId": "fc7a76db-a890-43c4-e3fa-e81066011e1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.0.post0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependencies"
      ],
      "metadata": {
        "id": "hZvx0Hizsbbm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LL-PBlpYHQVn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Any\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchmetrics\n",
        "from torchmetrics.text import CharErrorRate, WordErrorRate, BLEUScore\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mounting Drive"
      ],
      "metadata": {
        "id": "P2cI5_R85J9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3ksSZoi5MTs",
        "outputId": "e2567aad-8db2-4186-d626-8114344e0b77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "sIP3vGMZgYqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model  # embedding dimensionality\n",
        "        self.vocab_size = vocab_size    # size of corpus vocabulary\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)  # learnable vobabulary embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, sequence_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.sequence_len = sequence_len\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # creating a positional encoding matrix of dimension (sequence length, embedding dimensionality)\n",
        "        pos_enc = torch.zeros(sequence_len, d_model)\n",
        "        # creating positions vector of dimenstion (sequence length, 1)\n",
        "        positions = torch.arange(0, sequence_len, dtype=torch.float).unsqueeze(1)\n",
        "        divisor = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pos_enc[:, ::2] = torch.sin(positions * divisor)\n",
        "        pos_enc[:, 1::2] = torch.cos(positions * divisor)\n",
        "\n",
        "        # creating a positional encoding for a batch of embeddings of size (1, sequence length, embedding dimensionality)\n",
        "        pos_enc = pos_enc.unsqueeze(0)\n",
        "\n",
        "        # saving positional encoding as non-learnable parameter in same file as model weights\n",
        "        self.register_buffer('pos_enc', pos_enc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + (self.pos_enc[:, :x.shape[1], :]).requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LayerNormalizationBlock(nn.Module):\n",
        "    def __init__(self, eps: float = 10**-6) -> None:\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(1, device='cuda')) # Multiplicative parameter\n",
        "        self.beta = nn.Parameter(torch.zeros(1, device='cuda')) # Addative parameter\n",
        "\n",
        "    # input: (batch_size, seq_len, emb_dim)\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.layer1 = nn.Linear(d_model, d_ff).to(self.device)  # fc layer of dimension (ff_dim, emb_dim)\n",
        "        self.layer2 = nn.Linear(d_ff, d_model).to(self.device)  # fc layer of dimension (emb_dim, ff_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input: (batch_size, seq_len, emb_dim, ff_dim) --> (batch_size, seq_len, ff_dim, emb_dim) --> (batch_size, seq_len, emb_dim, ff_dim)\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.layer2(x)\n",
        "\n",
        "class MultiHeadSelfAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        assert d_model % h == 0, 'Embedding dimensionality not divisible by number of heads'\n",
        "        self.d_k = d_model // h\n",
        "\n",
        "        # learnable weight matrices\n",
        "        self.w_q = nn.Linear(d_model, d_model).to(self.device)\n",
        "        self.w_k = nn.Linear(d_model, d_model).to(self.device)\n",
        "        self.w_v = nn.Linear(d_model, d_model).to(self.device)\n",
        "        self.w_o = nn.Linear(d_model, d_model).to(self.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "\n",
        "        # input: (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            attention_scores.masked_fill_(mask == 0, -1**9)\n",
        "        # (batch, h, seq_len, seq_len)\n",
        "        attention_scores = torch.softmax(attention_scores, dim=-1)\n",
        "        if dropout is not None:\n",
        "            dropout(attention_scores)\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # input: (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        query = self.w_q(q)\n",
        "        key = self.w_k(k)\n",
        "        value = self.w_v(v)\n",
        "\n",
        "        # input: (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        x, self.attention_scores = MultiHeadSelfAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # input: (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k) # contiguous allows tensor shape to be changed in contiguous memory block\n",
        "\n",
        "        return self.w_o(x)\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = LayerNormalizationBlock()\n",
        "\n",
        "    def forward(self, skip_layer, prev_layer):\n",
        "        return skip_layer + self.dropout(prev_layer(self.norm(skip_layer)))\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, attention_block: MultiHeadSelfAttentionBlock, ff_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.attention_block = attention_block\n",
        "        self.ff_block = ff_block\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.residual_connections = nn.ModuleList(ResidualConnection(dropout) for _ in range(2))\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.attention_block(x, x, x, src_mask))\n",
        "        x = self.residual_connections[1](x, self.ff_block)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalizationBlock()\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, attention_block: MultiHeadSelfAttentionBlock, cross_attention_block: MultiHeadSelfAttentionBlock, ff_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.attention_block = attention_block\n",
        "        self.cross_attention_block = cross_attention_block\n",
        "        self.ff_block = ff_block\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.residual_connections = nn.ModuleList(ResidualConnection(dropout) for _ in range(3))\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.attention_block(x, x, x, tgt_mask))\n",
        "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "        x = self.residual_connections[2](x, self.ff_block)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalizationBlock()\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.projection = nn.Linear(d_model, vocab_size).to(self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input: (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "        return torch.log_softmax(self.projection(x), dim=-1) # log softmax for numerical stability\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_pos_enc: PositionalEncoding, tgt_pos_enc: PositionalEncoding, src_embed: TextEmbeddings, tgt_embed: TextEmbeddings, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pos_enc = src_pos_enc\n",
        "        self.tgt_pos_enc = tgt_pos_enc\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        src = self.src_embed(src)\n",
        "        src = self.src_pos_enc(src)\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, tgt, encoder_output, src_mask, tgt_mask,):\n",
        "        tgt = self.tgt_embed(tgt)\n",
        "        tgt = self.tgt_pos_enc(tgt)\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def projection(self, x):\n",
        "        return self.projection_layer(x)\n",
        "\n",
        "def BuildTransformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, h: int = 8, N: int = 6, d_ff: int = 2048, dropout: float = 0.1) -> Transformer:\n",
        "    # Create embedding layers\n",
        "    src_embedding = TextEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embedding = TextEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Create positional encodings\n",
        "    src_pos_enc = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos_enc = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    # Create encoder blocks\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        attention_block = MultiHeadSelfAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        encoder_block = EncoderBlock(attention_block, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    # Create decoder blocks\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        attention_block = MultiHeadSelfAttentionBlock(d_model, h, dropout)\n",
        "        cross_attention_block = MultiHeadSelfAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        decoder_block = DecoderBlock(attention_block, cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    # create encoder and decoder\n",
        "    encoder = Encoder(encoder_blocks)\n",
        "    decoder = Decoder(decoder_blocks)\n",
        "    # create projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "    # create transformer\n",
        "    transformer = Transformer(encoder, decoder, src_pos_enc, tgt_pos_enc, src_embedding, tgt_embedding, projection_layer)\n",
        "    # Initialize transformer parameters for better learning\n",
        "    for layer in transformer.parameters():\n",
        "        if layer.dim() > 1:\n",
        "            nn.init.xavier_uniform_(layer)\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "ubGAzOzmgamg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "0hmkyXWxgcoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
        "        super().__init__()\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_src.token_to_id('[PAD]')], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, index: Any) -> Any:\n",
        "        src_target_pair = self.ds[index]\n",
        "        src_txt = src_target_pair['translation'][self.src_lang]\n",
        "        tgt_txt = src_target_pair['translation'][self.tgt_lang]\n",
        "\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_txt).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_txt).ids\n",
        "\n",
        "        enc_num_pad_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
        "        dec_num_pad_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
        "\n",
        "        if enc_num_pad_tokens < 0:\n",
        "            enc_input_tokens = enc_input_tokens[:self.seq_len - 2]\n",
        "            enc_num_pad_tokens = 0\n",
        "        if dec_num_pad_tokens < 0:\n",
        "            dec_input_tokens = dec_input_tokens[:self.seq_len - 1]\n",
        "            dec_num_pad_tokens = 0\n",
        "\n",
        "        # Add SOS and EOS to source text\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * enc_num_pad_tokens, dtype=torch.int64)\n",
        "            ],\n",
        "            dim=0\n",
        "        )\n",
        "\n",
        "        # Add SOS to decoder input\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                torch.tensor([self.pad_token] * dec_num_pad_tokens, dtype=torch.int64)\n",
        "            ],\n",
        "            dim=0\n",
        "        )\n",
        "\n",
        "        # Add SOS to the label (expected decoder output)\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * dec_num_pad_tokens, dtype=torch.int64)\n",
        "            ],\n",
        "            dim=0\n",
        "        )\n",
        "\n",
        "        # Check to ensure the sizes of encoder, decoder, and label texts are of sequence length\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        # data set\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input, # size = seq_len\n",
        "            \"decoder_input\": decoder_input, # size = seq_len\n",
        "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n",
        "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & Causual_Mask(decoder_input.size(0)), # (1, seq_len) & (1, seq_len, seq_len)\n",
        "            \"label\": label, # (seq_len)\n",
        "            \"source_text\": src_txt,\n",
        "            \"target_text\": tgt_txt\n",
        "        }\n",
        "\n",
        "# returns a masked matrix with all values above diagonal masked out\n",
        "def Causual_Mask(size):\n",
        "    mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        ""
      ],
      "metadata": {
        "id": "QjLcHD_Zgivi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configurations"
      ],
      "metadata": {
        "id": "wWOgZ7vAgsl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_Config():\n",
        "    return{\n",
        "        \"batch_size\": 8,\n",
        "        \"num_epochs\": 20,\n",
        "        \"lr\": 10**-4,\n",
        "        \"seq_len\": 350,\n",
        "        \"d_model\": 512,\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"es\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"tmodel_\",\n",
        "        \"drive_path\": \"/content/drive/MyDrive/Colab/TranslationTransformer/\",\n",
        "        \"preload\": \"latest\",\n",
        "        \"tokenizer_filename\": \"tokenizer_{0}.json\",\n",
        "        \"experiment_name\": \"runs/tmodel\"\n",
        "    }\n",
        "\n",
        "def Get_Weights_File_Path(config, epoch: str):\n",
        "    drive_path = config['drive_path']\n",
        "    model_folder = config['model_folder']\n",
        "    model_basename = config['model_basename']\n",
        "    model_filename = f\"{model_basename}{epoch}.pt\"\n",
        "    return str(Path('.') / drive_path / model_folder / model_filename)\n",
        "\n",
        "def Get_Tokenizer_File_Path(config, lang: str):\n",
        "    drive_path = config['drive_path']\n",
        "    tokenizer_filename = Path(config['tokenizer_filename'].format(lang))\n",
        "    return str(Path('.') / drive_path / tokenizer_filename)\n",
        "\n",
        "def Get_Model_File_Path(config):\n",
        "    drive_path = config['drive_path']\n",
        "    model_folder = config['model_folder']\n",
        "    return str(Path('.') / drive_path / model_folder)\n",
        "\n",
        "# Find the latest weights file in the weights folder\n",
        "def Latest_Weights_File_Path(config):\n",
        "    model_folder = f\"{config['model_folder']}\"\n",
        "    model_filename = f\"{config['model_basename']}*\"\n",
        "    weights_files = list(Path(model_folder).glob(model_filename))\n",
        "    if len(weights_files) == 0:\n",
        "        return None\n",
        "    weights_files.sort()\n",
        "    return str(weights_files[-1])"
      ],
      "metadata": {
        "id": "qZtmlhdNgwuW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "GVCEYiEr4eF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Greedy_Decode(model, device, encoder_input, encoder_mask, src_tokenizer, tgt_tokenizer, max_len):\n",
        "    sos_idx = tgt_tokenizer.token_to_id('[SOS]')\n",
        "    eos_idx = tgt_tokenizer.token_to_id('[EOS]')\n",
        "\n",
        "    # Precompute encoder output and reuse it for every token we get from the decoder\n",
        "    encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "    # Initialize the decoder output with the SOS token\n",
        "    decoder_input = torch.empty(1,1).fill_(sos_idx).type_as(encoder_input).to(device)\n",
        "\n",
        "    while True:\n",
        "        # Break if decoder is max sequence length\n",
        "        if decoder_input.size(1) == max_len:\n",
        "            break\n",
        "\n",
        "        # build mask for the current decoder input\n",
        "        decoder_mask = Causual_Mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "        # calculate the decoder output\n",
        "        output = model.decode(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "\n",
        "        # get the next token\n",
        "        prob = model.projection(output[:, -1]) # project the output for the last token in the sequence\n",
        "        # select the token with the next highest probability\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        decoder_input = torch.cat([decoder_input, torch.empty(1,1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "        # break if next word is eos token\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "\n",
        "    # return generated sequence without batch dimension\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "def Run_Validation(model, device, val_ds, src_tokenizer, tgt_tokenizer, max_len, print_msg, global_step, writer, num_examples=2):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    console_width = 80 # size of control window\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "\n",
        "            # ensure validation batch is 1\n",
        "            assert encoder_input.size(0) == 1, 'Batch size must be 1 for validation'\n",
        "\n",
        "            # generate the output tokens\n",
        "            model_out = Greedy_Decode(model, device, encoder_input, encoder_mask, src_tokenizer, tgt_tokenizer, max_len)\n",
        "\n",
        "            # get actual model output\n",
        "            source_text = batch['source_text'][0]\n",
        "            target_text = batch['target_text'][0]\n",
        "            model_out_text = tgt_tokenizer.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "             # Print the source, target and model output\n",
        "            print_msg('-'*console_width)\n",
        "            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "\n",
        "            if count == num_examples:\n",
        "                print_msg('-'*console_width)\n",
        "                break\n",
        "\n",
        "            if writer:\n",
        "                # Evaluate the character error rate\n",
        "                # Compute the char error rate\n",
        "                metric = torchmetrics.CharErrorRate()\n",
        "                cer = metric(model_out_text, target_text)\n",
        "                writer.add_scalar('validation cer', cer, global_step)\n",
        "                writer.flush()\n",
        "\n",
        "                # Compute the word error rate\n",
        "                metric = torchmetrics.WordErrorRate()\n",
        "                wer = metric(model_out_text, target_text)\n",
        "                writer.add_scalar('validation wer', wer, global_step)\n",
        "                writer.flush()\n",
        "\n",
        "                # Compute the BLEU metric\n",
        "                metric = torchmetrics.BLEUScore()\n",
        "                bleu = metric(model_out_text, target_text)\n",
        "                writer.add_scalar('validation BLEU', bleu, global_step)\n",
        "                writer.flush()"
      ],
      "metadata": {
        "id": "HT9IM26I4gTQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "acoUP4UKg3CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_All_Sentances(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "def Get_or_Build_Tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Get_Tokenizer_File_Path(config, lang)\n",
        "    if not Path(tokenizer_path).exists():\n",
        "        print('Tokenizer not found, building...')\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=['[UNK]', '[PAD]', '[SOS]', '[EOS]'], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(Get_All_Sentances(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        print('Tokenizer found, loading...')\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "def Get_Dataset(config):\n",
        "    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split='train')\n",
        "\n",
        "    # Built tokenizer\n",
        "    tokenizer_src = Get_or_Build_Tokenizer(config, ds_raw, config['lang_src'])\n",
        "    tokenizer_tgt = Get_or_Build_Tokenizer(config, ds_raw, config['lang_tgt'])\n",
        "\n",
        "    # Split train and validation sets\n",
        "    train_ds_size = int(0.9 * len(ds_raw))\n",
        "    val_ds_size = len(ds_raw) -  train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "\n",
        "    max_len_src = 0\n",
        "    max_len_tgt = 0\n",
        "\n",
        "    for item in ds_raw:\n",
        "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
        "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
        "        max_len_src = max(max_len_src, len(src_ids))\n",
        "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "\n",
        "    print(f'Max length of source sentance: {max_len_src}')\n",
        "    print(f'Max length of target sentance: {max_len_tgt}')\n",
        "\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
        "\n",
        "def Get_Model(config, src_vocab_size, tgt_vocab_size):\n",
        "    model = BuildTransformer(src_vocab_size, tgt_vocab_size, config['seq_len'], config['seq_len'], config['d_model'])\n",
        "    return model\n",
        "\n",
        "def Train_model(config):\n",
        "    # setting device to train on\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device {device}')\n",
        "\n",
        "    # Create file for parameters to be saved to\n",
        "    model_folder = Get_Model_File_Path(config)\n",
        "    Path(model_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Initialize dataloaders and tokenizers\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = Get_Dataset(config)\n",
        "\n",
        "    # Initialize model\n",
        "    model = Get_Model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "    # Create a tensorboard for loss visualization\n",
        "    writer = SummaryWriter(config['experiment_name'])\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    # Initial epoch start and global stop of this training cycle\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    # preload previous model parameters if they exist\n",
        "    if config['preload'] == \"latest\":\n",
        "        model_filename = Latest_Weights_File_Path(config)\n",
        "        print(f'Preloading model {model_filename}')\n",
        "        state = torch.load(model_filename)  # loading previous model state\n",
        "        initial_epoch = state['epoch'] + 1\n",
        "        model.load_state_dict(state['model_state_dict'])\n",
        "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "        global_step = state['global_step']\n",
        "        print(f'Starting training at epoch {initial_epoch}')\n",
        "    else:\n",
        "      model_filename = Get_Model_File_Path(config, config['preload'])\n",
        "      print(f'No model found to preload')\n",
        "\n",
        "    # Initializing loss function\n",
        "    # Ignores any padded tokens in loss computation\n",
        "    # Smoothes result by distributing .1 of argmax value to all other labels\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        # Initialize batch iterator using tqdm for a progression bar visualization\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f'Processing epoch {epoch:02d}')\n",
        "        for batch in batch_iterator:\n",
        "            if batch == None:\n",
        "                continue\n",
        "            encoder_input = batch['encoder_input'].to(device)   # input: (batch, seq_len)\n",
        "            decoder_input = batch['decoder_input'].to(device)   # input: (batch, seq_len)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)     # (batch, 1, 1, seq_len) to mask padded tokens\n",
        "            decoder_mask = batch['decoder_mask'].to(device)     # (batch, 1, seq_len, seq_len) to mask padded tokens and future words\n",
        "\n",
        "            # run tensors through model\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)  # (batch, seq_len, d_model)\n",
        "            decoder_output = model.decode(decoder_input, encoder_output, encoder_mask, decoder_mask)    # (batch, seq_len, d_model)\n",
        "            projection_output = model.projection(decoder_output)    # (batch, seq_len, tgt_vocab_size)\n",
        "            # Get label from batch\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            # input (batch, seq_len, tgt_vocab_size) --> (batch * seq_len, tgt_vocab_size)\n",
        "            loss = loss_fn(projection_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "\n",
        "            # update the progress bar with the loss\n",
        "            batch_iterator.set_postfix({f'loss': f'{loss.item():6.3f}'})\n",
        "\n",
        "            # log the loss in tensorboard\n",
        "            writer.add_scalar('train loss', loss.item(), global_step)\n",
        "            writer.flush()\n",
        "\n",
        "            # Backpropogate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # Save the model at the end of every epoch\n",
        "        model_filename = Get_Weights_File_Path(config, f'{epoch:02d}')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n",
        "\n",
        "        # Run validation at the end of each epoch\n",
        "        Run_Validation(model, device, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], lambda msg: batch_iterator.write(msg), global_step, writer)"
      ],
      "metadata": {
        "id": "ZHVIuO16g2mN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "BhcrbirVPBnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Get_Config()\n",
        "Train_model(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCOa-K8xg-6i",
        "outputId": "3698dc28-004e-4800-9b0a-77ad337fe29c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n",
            "Tokenizer found, loading...\n",
            "Tokenizer found, loading...\n",
            "Max length of source sentance: 767\n",
            "Max length of target sentance: 782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 00: 100%|██████████| 10516/10516 [26:30<00:00,  6.61it/s, loss=4.629]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: How could you have consoled her!--I cannot express my own abhorrence of myself.\n",
            "    TARGET: ¡Cómo habría perdurado en tus recuerdos! ¡Y mi madre, también!\n",
            " PREDICTED: - Pero , que la señora , que la que la que la que la que la , que la , que la , que la , que la , que la , que la , que la , que , que , que , que , que no , que , , , , que , , , , que , , , , , , , , , , , , , que , , , , , , , , , , de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: And the Eaglet bent down its head to hide a smile: some of the other birds tittered audibly.\n",
            "    TARGET: Y el Aguilucho bajó la cabeza para ocultar una sonrisa; algunos de los otros pájaros rieron sin disimulo.\n",
            " PREDICTED: Y , que la , que la , que la , , que la , , , , , ,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 01: 100%|██████████| 10516/10516 [26:31<00:00,  6.61it/s, loss=5.868]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"So, as I was saying,\" continued Sancho, \"as the pair of them were going to sit down to table, as I said, the labourer insisted upon the gentleman's taking the head of the table, and the gentleman insisted upon the labourer's taking it, as his orders should be obeyed in his house; but the labourer, who plumed himself on his politeness and good breeding, would not on any account, until the gentleman, out of patience, putting his hands on his shoulders, compelled him by force to sit down, saying, 'Sit down, you stupid lout, for wherever I sit will be the head to you; and that's the story, and, troth, I think it hasn't been brought in amiss here.\"\n",
            "    TARGET: -«Digo, así -dijo Sancho-, que, estando, como he dicho, los dos para sentarse a la mesa, el labrador porfiaba con el hidalgo que tomase la cabecera de la mesa, y el hidalgo porfiaba también que el labrador la tomase, porque en su casa se había de hacer lo que él mandase; pero el labrador, que presumía de cortés y bien criado, jamás quiso, hasta que el hidalgo, mohíno, poniéndole ambas manos sobre los hombros, le hizo sentar por fuerza, diciéndole: ''Sentaos, majagranzas, que adondequiera que yo me siente será vuestra cabecera''.» Y éste es el cuento, y en verdad que creo que no ha sido aquí traído fuera de propósito.\n",
            " PREDICTED: - Y , Sancho , señor , Sancho , Sancho , y , y , a la venta , y , a la mesa , y , y , y , que , y , como si , y , y , como , como si , y , como si , y , y , y , como si , como si , como si , como si , como si , como si , como si se le dijo , como si , como si , como si , y , como si , como si no , y , como si , que , y , que , como si , que , y , como si , como si , que , como si , como si , como si , como si , que , que , si , que , que , como si no se le dijo , que , que , que , que , como si el cura , que , como si no se puso en el cura , que , que , como si no se ha dicho , que , señor , como si se ha dicho , como vuestra merced , que , como si no se ha dicho , señor , señor don Quijote , Sancho , señor don Quijote , que , que , que , que , que , que , como si no se puso a Sancho , señor , señor don Quijote , que , que , que , señor , que , y , señor , y , señor don Quijote , señor , que , que , que , y , y , y , y , que no le dijo , que , no se puso en el cual , que no se le dijo , señor don Quijote , no se le dijo , y , no se le dijo don Quijote -, que se le dijo don Quijote , y , y , que no se le dijo don Quijote , y , que , señor\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Somewhere there, on that desolate plain, was lurking this fiendish man, hiding in a burrow like a wild beast, his heart full of malignancy against the whole race which had cast him out.\n",
            "    TARGET: En algún lugar de aquella llanura desolada se escondía el diabólico asesino, oculto en un escondrijo como una bestia salvaje y con el corazón lleno de malevolencia hacia toda la raza humana que lo había expulsado de su seno.\n",
            " PREDICTED: En aquel momento en el que el que había hecho un hombre que había hecho en el hombre que había hecho en el hombre que había hecho en el hombre que había hecho un hombre que había hecho en el que había hecho en el hombre que había hecho en el cual había hecho en el hombre que había hecho en el que había hecho en el hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho en el hombre que había hecho un hombre que había hecho en el hombre que había hecho en el cual había hecho un hombre que había hecho un hombre que había hecho en el hombre que había hecho en el hombre que había hecho en el hombre que había hecho un hombre que había hecho un hombre que había hecho en el hombre que había hecho un hombre que el hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho en el hombre que había hecho un hombre que había hecho un hombre que había hecho en un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre hombre que había hecho un hombre que había hecho en el hombre que había hecho en el hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había hecho un hombre que había\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 02: 100%|██████████| 10516/10516 [26:24<00:00,  6.64it/s, loss=5.288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Cyrus Harding looked at his dog, and those of his companions who were near him might have heard him murmur these words,--\n",
            "    TARGET: Ciro Smith miraba a Top y, si alguno de sus compañeros se hubiera acercado al ingeniero en aquel momento, le habría oído murmurar:\n",
            " PREDICTED: Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y sus compañeros , y Ciro Smith y sus compañeros , y Ciro Smith y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , Ciro Smith y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros y sus compañeros , y sus compañeros , Ciro Smith y sus compañeros , y sus compañeros , y , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros y sus compañeros , Ciro Smith , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , y sus compañeros , Ciro Smith y que Ciro Smith y sus compañeros , sus compañeros , Ciro Smith y , y sus compañeros , Ciro Smith y sus compañeros , Ciro Smith , Ciro Smith y sus compañeros , Ciro Smith y sus compañeros , sus compañeros , y sus compañeros , Ciro Smith y sus compañeros se había estado en sus compañeros , Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y Ciro Smith y sus compañeros , Ciro Smith , Ciro Smith y sus compañeros , Ciro Smith , Ciro Smith y sus compañeros , Ciro Smith y Ciro Smith y los que Ciro Smith y Ciro Smith y Ciro Smith , Ciro Smith y Ciro Smith , Ciro Smith y Ciro Smith y Ciro Smith y sus compañeros , y sus compañeros , Ciro Smith y no se habían vuelto a Ciro Smith y Ciro Smith , Ciro Smith , Ciro Smith , Ciro Smith y sus compañeros , no se había estado de Ciro Smith y Ciro Smith y Ciro Smith y sus compañeros , Ciro Smith , Ciro Smith , Ciro Smith , Ciro Smith , Ciro Smith , Ciro\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Yes, my boy.\n",
            "    TARGET: -En efecto.\n",
            " PREDICTED: Sí , sí , sí , sí , lo que , lo que lo que , lo que , lo que lo que lo que lo que le dijo : - Sí , lo que lo que lo que lo que lo que lo que lo que le había hecho lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que le había hecho lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que le había hecho lo que lo que lo que lo que lo que lo que es lo que es lo que es que es lo que lo que lo que lo que lo que lo que lo que lo que lo que es que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que sí mismo que lo que lo que lo que lo que lo que lo que lo que lo que lo que lo que es lo que mi lado es mi vida .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 03: 100%|██████████| 10516/10516 [26:30<00:00,  6.61it/s, loss=4.824]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Where is the humiliation?\n",
            "    TARGET: –¿Dónde está la ofensa?\n",
            " PREDICTED: –¿ Y qué es decir , ¿ Dónde está ? – dijo : –¿ Y quién ? – preguntó a la –¿ Y quién ? – preguntó el –¿ Y qué ?\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Well, if you are cold, Planchet, you can go into one of those cabarets that you see yonder, and be in waiting for me at the door by six o’clock in the morning.\"\n",
            "    TARGET: Bueno, si tienes frío, Planchet, entra en una de esas tabernas que ves allá abajo, y me esperas mañana a las seis delante de la puerta.\n",
            " PREDICTED: – Pues bien , que , que , que , que , que , que , que , que , que se ha dicho que , que , que ha dicho , que se ha de que , que se ha dicho , que , que se ha de la puerta , que se ha de que , que ha de la puerta , que vos , que , que ha de que se ha de la mañana , que no se ha dicho , que se ha dicho , que no se ha venido a la mañana , que vos , que se ha dicho , que se ha dicho que vos , que no se ha de la mañana , que se ha dicho , que se ha dicho , que se ha dicho que se ha dicho que se ha pasado mañana , que os ha dicho que se ha dicho que se ha de la puerta , que ha dicho que ha dicho que ha dicho , que ha pasado , que vos , que ha pasado , señor , señor , que ha dicho , señor , que ha de la mañana , que ha pasado mañana , que ha pasado mañana os ha pasado mañana , que vos habéis de la mañana , señor , señor Willoughby , señor , que ha pasado mañana , señor , que ha pasado seis de las diez de las seis , señor , señor Willoughby , señor Willoughby , que no menos que se ha dicho que no se ha pasado mañana , señor , señor cardenal , señor , se ha dicho , señor , que no se ha de las seis , señor , señor , no ha venido a vuestra merced , señor D ' Artagnan no ha vuelto a la mañana , señor , no está en la mañana , no se ha pasado mañana os ha salido a la puerta , señor D ' Artagnan , señor , señor , señor Willoughby , que no ha pasado mañana , no ha\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 04: 100%|██████████| 10516/10516 [26:23<00:00,  6.64it/s, loss=4.920]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Being much less cool-headed than Mr. Fogg, he was much more restless, counting and recounting the days passed over, uttering maledictions when the train stopped, and accusing it of sluggishness, and mentally blaming Mr. Fogg for not having bribed the engineer.\n",
            "    TARGET: Contaba y volvía a contar los días transcurridos, maldecía las paradas del tren, lo acusaba de lentitud y vituperaba \"in pectore\" a mister Fogg por no haber prometido una prima al maquinista. No sabía el buen muchacho que lo que era posible en un vapor no tenía aplicación en un ferrocarril, cuya velocidad era reglamentaria.\n",
            " PREDICTED: A pesar de Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , y , y Phileas Fogg , y Phileas Fogg , Phileas Fogg , y Phileas Fogg , señor Phileas Fogg , señor Fix , y , señor Fix , señor Fix , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Fix , señor Phileas Fogg , mister Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , y Phileas Fogg , mister Fogg , señor Phileas Fogg , señor Phileas Fogg , mister Fogg , y Phileas Fogg , mister Fogg , Phileas Fogg , mister Fogg , mister Fogg , señor Phileas Fogg , y , y Phileas Fogg , señor Phileas Fogg , mister Fogg , mister Fogg , señor Phileas Fogg , mister Fogg , y Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg y Phileas Fogg , mister Fogg , señor Fix , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Phileas Fogg , señor Phileas Fogg , señor Fix , señor Fix , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Fogg , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Phileas Fogg , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Fix , señor Phileas Fogg , señor Fix , señor Fix , señor Phileas Fogg , señor Phileas Fogg , señor Phileas Fogg , señor Fix , señor Phileas Fogg , señor\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: And he got up very sulkily and crossed over to the other side of the court.\n",
            "    TARGET: Se levantó con aire digno y fue a situarse al otro extremo de la sala.\n",
            " PREDICTED: Y , Y , que el otro lado , el otro , que el otro lado , que el otro lado , que se puso a la orden de la que se puso a la otra vez , se había hecho de la habitación , se puso a la otra cosa , se , se , se ha venido a la orden de la calle , se , y se , se ha hecho de la sala de la corte .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 05: 100%|██████████| 10516/10516 [26:26<00:00,  6.63it/s, loss=4.636]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I went to my window, opened it, and looked out.\n",
            "    TARGET: Abrí la ventana y miré al exterior.\n",
            " PREDICTED: , miré a la ventana , y miró a la ventana , y , y a la ventana , y a la ventana , y , y a la ventana , y a la ventana , y a la ventana , y , y a la ventana , y , y me abrió y , y , y , y , y , y , y , y me abrió y , y me hizo entrar en la ventana , y me hizo .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"I say then,\" continued Sancho, \"that in a village of Estremadura there was a goat-shepherd—that is to say, one who tended goats—which shepherd or goatherd, as my story goes, was called Lope Ruiz, and this Lope Ruiz was in love with a shepherdess called Torralva, which shepherdess called Torralva was the daughter of a rich grazier, and this rich grazier-\"\n",
            "    TARGET: -«Digo, pues -prosiguió Sancho-, que en un lugar de Estremadura había un pastor cabrerizo (quiero decir que guardaba cabras), el cual pastor o cabrerizo, como digo, de mi cuento, se llamaba Lope Ruiz; y este Lope Ruiz andaba enamorado de una pastora que se llamaba Torralba, la cual pastora llamada Torralba era hija de un ganadero rico, y este ganadero rico...»\n",
            " PREDICTED: - Así , Sancho - prosiguió Sancho - respondió Sancho - respondió Sancho -, que fue a Sancho -, que fue Sancho - respondió Sancho - respondió Sancho - respondió Sancho , que fue Sancho , que fue a Sancho Panza , que fue a Sancho - respondió Sancho - que dice que fue a Sancho , que fue a Sancho - que fue a esta hermosa Dorotea -, que se , que , que fue a esta historia , que fue a esta historia , que fue una hermosa Dorotea , que fue el cabrero - que fue una hermosa Dorotea , que fue hermosa Dorotea , que fue una historia que este tiempo que fue a esta sazón Sancho Panza , que fue desta doncella , que es - que este tiempo que fue una hija , que fue , que fue a Sancho - que este tiempo que dice - que este gigante - que dice - Pues que este tiempo que dice Sancho - Pues , señor don Quijote -, que dice - que dice Sancho -, que dice Sancho - dice Sancho - respondió Sancho - respondió Sancho Panza - respondió Sancho Panza , que dice Sancho Panza dice que dice Sancho Panza -, que dice Sancho Panza , Sancho - respondió Sancho - respondió Sancho - Digo que dice Sancho Panza -, que Sancho Panza - respondió Sancho Panza - respondió Sancho - respondió Sancho - respondió Sancho Panza - respondió Sancho Panza , que Sancho Panza - respondió Sancho Panza -, que dice que fue una hermosa Dorotea -, que Sancho - que dice Sancho - que Sancho - que Sancho - respondió Sancho - respondió Sancho - respondió Sancho -, que dice Sancho , que Sancho -, que dice Sancho - Pues , que dice Sancho -, que fuere servido - que fue Sancho - respondió Sancho - respondió Sancho -, que dice Sancho - respondió Sancho - replicó Sancho -, que Sancho Panza - respondió Sancho -, que fue la cual fue el cual fue llamada Dorotea -,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 06: 100%|██████████| 10516/10516 [26:28<00:00,  6.62it/s, loss=5.036]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: You don't hesitate to take a place at my side, do you?\n",
            "    TARGET: ¿Acaso teme sentarse a mi lado?\n",
            " PREDICTED: – No os place , ¿ No os habéis hecho usted a mi lado , ¿ No os habéis venido a vos ?\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: In the middle of the night, and under all the rest of our distresses, one of the men that had been down to see cried out we had sprung a leak; another said there was four feet water in the hold.\n",
            "    TARGET: A medianoche, y para colmo de nuestras desgracias, uno de los hombres que había bajado a ver la situación, gritó que teníamos una grieta y otro dijo que teníamos cuatro pies de agua en la bodega.\n",
            " PREDICTED: En medio de ver que se había sido una noche , el cual , que se había sido una noche , que había sido una noche , que había estado de ver que se había estado de ver a ver que había estado de ver que había estado de ver a ver que había estado de la noche , que había estado de la noche , que había estado de la noche , se había estado de la noche , y de la noche , que se había estado de la noche , y el cual había estado de la noche ! dijo que había sido una noche , que había estado de la noche .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 07: 100%|██████████| 10516/10516 [26:25<00:00,  6.63it/s, loss=3.972]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Some day a son may be born, my son, and he will by law be a Karenin, and not heir either to my name or my property, and however happy we may be in our family life, and whatever children we may have, there will be no legal bond between them and me.\n",
            "    TARGET: Alexey continuó: –Mañana podemos tener un hijo. Por la naturaleza será hijo mío; por la ley, será Karenin, y no podrá ser el heredero de mi fortuna.\n",
            " PREDICTED: – Mi hijo mío , y mi nombre y puede ser mi nombre y mi nombre y mi hijo y mi nombre y mi nombre y a mi nombre y , y mi nombre y mi nombre y mi nombre y mi nombre y mi nombre y mi nombre y mi nombre , hijo mío , y mi cuñado y mi nombre y mi nombre y mi nombre y mi vida , y mi nombre y no puede ser mi hijo mío y mi nombre y mi nombre y mi vida y mi vida y mi vida y mi vida ; y no puede ser mi nombre y mi nombre y mi vida y mi nombre y mi nombre y mi hijo mío y mi vida y mi nombre de mi nombre , y mi nombre y mi nombre y el hijo mío y mi nombre de mi vida y mi vida y mi vida , y mi vida y el heredero hijos míos y mi vida , y mi vida , y mi nombre y mi hijo mío y mi nombre y mi nombre y mi nombre y mi nombre y mi hijo mío ''.\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: But enough – enough about it!' and he got up.\n",
            "    TARGET: Bien; basta. No hablemos más de eso –añadió, levantándose.\n",
            " PREDICTED: Pero , todo esto , todo esto ! – Y , todo esto ! – Pero , todo esto ! – Pero , ¡ Pero , ¡ Y qué es necesario ! – Pero , ¡ Pero esto !\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 08: 100%|██████████| 10516/10516 [26:26<00:00,  6.63it/s, loss=4.538]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I am going through the City first, and we can have some lunch on the way.\n",
            "    TARGET: Antes tengo que pasar por la City, y podemos comer algo por el camino.\n",
            " PREDICTED: A propósito de volver a través de volver a través de volver a través de volver a través de volver a través de volver a través de volver a través de llegar a través de llegar a través de la City .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: WHICH TREATS OF THE EXALTED ADVENTURE AND RICH PRIZE OF MAMBRINO'S HELMET, TOGETHER WITH OTHER THINGS THAT HAPPENED TO OUR INVINCIBLE KNIGHT\n",
            "    TARGET: Que trata de la alta aventura y rica ganancia del yelmo de Mambrino, con otras cosas sucedidas a nuestro invencible caballero\n",
            " PREDICTED: Que trata de la aventura de la aventura de la aventura de la aventura de la de la aventura de la aventura de la historia\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 09: 100%|██████████| 10516/10516 [26:29<00:00,  6.62it/s, loss=4.436]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Je préfere de beaucoup loger avec un camarade que vivre tout seul. »\n",
            "    TARGET: El joven Stamford, el vaso en la mano, me miró de forma un tanto extraña.\n",
            " PREDICTED: En todo lo largo tiempo para mí mismo tiempo que he visto en el tiempo para mí .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"There goes one!\" cried Athos, at the end of five hundred paces.\n",
            "    TARGET: ¡Unol dijo Athos al cabo de quinientos pasos.\n",
            " PREDICTED: ¡ Y Athos ! exclamó Athos ! exclamó Athos ! exclamó Athos ! exclamó Athos ! exclamó Athos ! exclamó Athos ! exclamó Athos ! ¡ Athos ! exclamó Athos ! exclamó Athos !\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 10: 100%|██████████| 10516/10516 [26:29<00:00,  6.62it/s, loss=3.909]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: She stood with her figure outlined against the flood of light, one hand upon the door, one half-raised in her eagerness, her body slightly bent, her head and face protruded, with eager eyes and parted lips, a standing question.\n",
            "    TARGET: Permaneció inmóvil, con su silueta recortada contra la luz, una mano apoyada en la puerta, la otra a medio alzar en un gesto de ansiedad, el cuerpo ligeramente inclinado, adelantando la cabeza y la cara, con ojos impacientes y labios entreabiertos. Era la estampa viviente misma de la incertidumbre.\n",
            " PREDICTED: Kitty miraba con una mano , con la mano con una sonrisa , con una mano , con una de la cabeza inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada y con una expresión de la cabeza inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada ligeramente inclinada sobre la cabeza inclinada sobre la cabeza , con una figura y , con una sonrisa , con una sonrisa , con una sonrisa , con una sonrisa .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Professor, these same instruments are found in my stateroom, where I'll have the pleasure of explaining their functions to you.\n",
            "    TARGET: -Señor profesor, esos instrumentos están también en mi camarote, y es allí donde tendré el placer de explicarle su empleo.\n",
            " PREDICTED: - Señor - Señor - Señor - Señor - Señor - Señor , donde están en el mismo , donde están en el mismo , donde el mismo tiempo , donde están en el mío .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 11: 100%|██████████| 10516/10516 [26:30<00:00,  6.61it/s, loss=4.408]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Pshaw, my dear fellow, what do the public, the great unobservant public, who could hardly tell a weaver by his tooth or a compositor by his left thumb, care about the finer shades of analysis and deduction!\n",
            "    TARGET: ––Psé. Querido amigo, ¿qué le importan al público, al gran público despistado, que sería incapaz de distinguir a un tejedor por sus dientes o a un cajista de imprenta por su pulgar izquierdo, los matices más delicados del análisis y la deducción?\n",
            " PREDICTED: -¡ Qué cree que qué cree que se lo que por el que se lo que se lo que el que el que el que había producido por el que por el que el que el que el que el pulgar , que lo que se lo que sí mismo tiempo que dice bien el pulgar , que se dice bien conocido por qué sirve para el que lo que dice bien conocido por el pulgar , que es decir que sea el trabajo , que lo que sea el que el arma que el que lo que lo que dice el gusto de su pulgar , que lo que lo que lo que lo que el pulgar , que el más tiempo que lo que dice lo que es lo que lo que dice que el más que lo que lo que dice el que no ha sido el que lo que dice que el que el que el tiempo maravilloso volumen de su propietario .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"This is most important,\" said he when I had concluded. \"It fills up a gap which I had been unable to bridge, in this most complex affair.\n",
            "    TARGET: -Todo eso es de gran importancia en este asunto tan complicado -dijo cuando terminé-, porque colma una laguna que yo había sido incapaz de llenar.\n",
            " PREDICTED: - Esto es importante », dijo -, que no es importante -, que no es importante que no poder estar muy importante que no es importante para que no es importante que no es importante que no es importante para que sea importante es importante que no es importante que es importante que no es importante que es importante .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 12: 100%|██████████| 10516/10516 [26:29<00:00,  6.62it/s, loss=4.693]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Come, come, calm yourself, my sweet girl!\n",
            "    TARGET: Mas esto es más que odio, esto es ingratitud.\n",
            " PREDICTED: Vamos , ¡ Ven ! ¡ ¡ Ven ! ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ! ¡ ! ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ! ¡ ¡ ¡ ! ¡ ¡ ¡ ! ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ! ¡ ¡ ! ¡ ! ¡ ! ¡ ¡ ¡ ¡ ¡ ¡ ¡ !\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He wore a long-skirted blue coat with buttons very low down at the back, high boots drawn quite straight over the calves of his legs and crinkled round the ankles, and over them he had on a pair of large goloshes.\n",
            "    TARGET: Tenía los ojos saltones y turbios. Vestía una larga levita azul, con botones muy bajos en los faldones, y calzaba botas altas, arrugadas en los tobillos y rectas en las piernas, protegidas por grandes chanclos.\n",
            " PREDICTED: Salió del círculo , pasear con el patio azul , y los grandes saltos y muy alto , muy alta , muy hermosos y allí , y muy alto , y botas altas botas altas botas poco de manera muy poco de los pies sobre el suelo muy elegante y muy poco , muy poco de manera muy alto , muy alto y botas altas botas altas botas altas botas altas botas altas botas altas botas poco .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 13: 100%|██████████| 10516/10516 [26:35<00:00,  6.59it/s, loss=4.541]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Then it will be necessary to waken him and take him with us,\" said the renegade, \"and everything of value in this fair mansion.\"\n",
            "    TARGET: ''Pues será menester despertalle -replicó el renegado-, y llevárnosle con nosotros, y todo aquello que tiene de valor este hermoso jardín.''\n",
            " PREDICTED: - dijo el renegado dijo el renegado dijo el renegado dijo : \" dijo Ana -, y dijo : el renegado a sí ; y el renegado le dijo : - dijo : - dijo :\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: When Sancho heard his master's firm, resolute language, a cloud came over the sky with him and the wings of his heart drooped, for he had made sure that his master would not go without him for all the wealth of the world; and as he stood there dumbfoundered and moody, Samson Carrasco came in with the housekeeper and niece, who were anxious to hear by what arguments he was about to dissuade their master from going to seek adventures.\n",
            "    TARGET: Cuando Sancho oyó la firme resolución de su amo se le anubló el cielo y se le cayeron las alas del corazón, porque tenía creído que su señor no se iría sin él por todos los haberes del mundo; y así, estando suspenso y pensativo, entró Sansón Carrasco y la sobrina, deseosos de oír con qué razones persuadía a su señor que no tornarse a buscar las aventuras.\n",
            " PREDICTED: Cuando llegaba el don Quijote , y habló de su amo , y el del mundo , y el que no se vio a su señor ; y el corazón de su amo y , y el corazón de su señor don Quijote y el que se su amo , y el corazón de su señor ; y el mundo y el mundo .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 14: 100%|██████████| 10516/10516 [26:32<00:00,  6.60it/s, loss=4.023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The intensity of these underground forces continues to diminish.\n",
            "    TARGET: La violencia de las fuerzas subterráneas va decreciendo cada vez más.\n",
            " PREDICTED: La intensidad de aquellas condiciones de la fatiga .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: It's about Isa.\n",
            "    TARGET: Se trata de Isa.\n",
            " PREDICTED: En el cual se había llegado a la salida del cual se había llegado a los trabajos .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 15: 100%|██████████| 10516/10516 [26:27<00:00,  6.62it/s, loss=3.657]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Scissors were made among other things, and the settlers were at last able to cut their hair, and also to shave, or at least trim their beards.\n",
            "    TARGET: Se fabricaron tijeras y los colonos pudieron cortarse el pelo y, si no afeitarse, por lo menos arreglarse la barba.\n",
            " PREDICTED: Los colonos tenían las barbas y entre otras cosas habían podido disparar algunos elementos debían corresponder a los otros habían podido pasar adelante sus vestidos , los otros habían podido ser rica , y otras cosas habían podido hacerlo .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: That day the Nautilus was put to work in some depth-sounding experiments that fascinated me deeply.\n",
            "    TARGET: Aquel día, se sometió al Nautilus a diversos experimentos de sondeo que me interesaron vivamente.\n",
            " PREDICTED: Aquel día siguiente , yo me produjo bajo el Nautilus me puse en el Nautilus me puse en aquel día en busca de mí me las cercanías del Nautilus .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 16: 100%|██████████| 10516/10516 [26:27<00:00,  6.62it/s, loss=3.623]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: About five ft. seven in. in height; strongly built, sallow complexion, black hair, a little bald in the centre, bushy, black side-whiskers and moustache; tinted glasses, slight infirmity of speech.\n",
            "    TARGET: Estatura, unos cinco pies y siete pulgadas; complexión fuerte, piel atezada, cabello negro con una pequeña calva en el centro, patillas largas y bigote negro; gafas oscuras, ligero defecto en el habla.\n",
            " PREDICTED: Hacia las siete segundos negra , con una altura , que se acercó a siete segundos , pelo negro , que una altura , que se acercó a la altura , que negros , que se acercó a la altura , con aspecto de sus siete años atrás .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Still more; as soon as Monsieur had left and disappeared round the corner of the street, Monsieur Bonacieux took his hat, shut his door, and set off at a quick pace in an opposite direction.\"\n",
            "    TARGET: Además, tan pronto como el señor le ha dejado y ha desaparecido por la esquina de la calle, el señor Bonacieux ha cogido su sombrero, ha cerrado su puerta y se ha puesto a correr en dirección contraria.\n",
            " PREDICTED: Sin embargo , señor Bonacieux se precipitó hacia el señor Bonacieux se marchó al señor Bonacieux se dejó paso , se encontró en el sombrero en la puerta , y desapareció detrás de la vuelta al señor Bonacieux .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 17: 100%|██████████| 10516/10516 [26:31<00:00,  6.61it/s, loss=3.591]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The prisoner turned with the reckless air of a man who abandons himself to his destiny. \"Be it so,\" said he.\n",
            "    TARGET: ¡Lo reconozco por las fotografías! El preso se volvió con el aire indiferente de quien se abandona en manos del destino. ––De acuerdo ––dijo––.\n",
            " PREDICTED: Sea dijo el destino , que el destino ; el destino , que el destino , que se volvió a su destino ; el destino ; el destino .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Then you have been in Paraguay?\" asked Candide.\n",
            "    TARGET: ¿Con que tu ya has estado en el Paraguay? le dixo Candido.\n",
            " PREDICTED: ¿ Y en el caso ? – preguntó el momento ? - preguntó Candido .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 18: 100%|██████████| 10516/10516 [26:29<00:00,  6.62it/s, loss=3.899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: And is Philip the gardener really still living?\n",
            "    TARGET: ¿Y la casa? ¿Sigue como antes?\n",
            " PREDICTED: Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ¿ Y ahora ?\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: D’Artagnan fought three times with Rochefort, and wounded him three times.\n",
            "    TARGET: D'Artagnan se batió tres veces con Rochefort y lo hirió tres veces.\n",
            " PREDICTED: D ' Artagnan tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces tres veces .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 19: 100%|██████████| 10516/10516 [26:30<00:00,  6.61it/s, loss=3.646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The information about Mr. John's death and the manner of it came too suddenly: it brought on a stroke.\n",
            "    TARGET: Las pérdidas de dinero y el temor a la pobreza la han empeorado. Y la brusca noticia del suicidio del señorito le produjo un ataque.\n",
            " PREDICTED: El señor John apareció una información , y se trata de pronto , y la muerte de pronto , y muy poco de pronto como un poco de repente .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I have a horror of fallen women.\n",
            "    TARGET: Aborrezco a las mujeres perdidas.\n",
            " PREDICTED: ¿ Y las mujeres , y las mujeres , y las mujeres .\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}